{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reviews_train = []\n",
    "for line in open('c:/Users/Engit/Desktop/bitirme_projesi/movie_data/full_train.txt','r',encoding='utf8'):\n",
    "    \n",
    "    reviews_train.append(line.strip())\n",
    "    \n",
    "reviews_test = []\n",
    "for line in open('C:/Users/Engit/Desktop/bitirme_projesi/movie_data/full_test.txt','r',encoding='utf8'):\n",
    "    \n",
    "    reviews_test.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"This isn't the comedic Robin Williams, nor is it the quirky/insane Robin Williams of recent thriller fame. This is a hybrid of the classic drama without over-dramatization, mixed with Robin's new love of the thriller. But this isn't a thriller, per se. This is more a mystery/suspense vehicle through which Williams attempts to locate a sick boy and his keeper.<br /><br />Also starring Sandra Oh and Rory Culkin, this Suspense Drama plays pretty much like a news report, until William's character gets close to achieving his goal.<br /><br />I must say that I was highly entertained, though this movie fails to teach, guide, inspect, or amuse. It felt more like I was watching a guy (Williams), as he was actually performing the actions, from a third person perspective. In other words, it felt real, and I was able to subscribe to the premise of the story.<br /><br />All in all, it's worth a watch, though it's definitely not Friday/Saturday night fare.<br /><br />It rates a 7.7/10 from...<br /><br />the Fiend :.\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_train[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "REPLACE_NO_SPACE = re.compile(\"(\\.)|(\\;)|(\\:)|(\\!)|(\\')|(\\?)|(\\,)|(\\\")|(\\()|(\\))|(\\[)|(\\])|(\\d+)\")\n",
    "REPLACE_WITH_SPACE = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n",
    "NO_SPACE = \"\"\n",
    "SPACE = \" \"\n",
    "\n",
    "def preprocess_reviews(reviews):\n",
    "    \n",
    "    reviews = [REPLACE_NO_SPACE.sub(NO_SPACE, line.lower()) for line in reviews]\n",
    "    reviews = [REPLACE_WITH_SPACE.sub(SPACE, line) for line in reviews]\n",
    "    \n",
    "    return reviews\n",
    "\n",
    "reviews_train_clean = preprocess_reviews(reviews_train)\n",
    "reviews_test_clean = preprocess_reviews(reviews_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this isnt the comedic robin williams nor is it the quirky insane robin williams of recent thriller fame this is a hybrid of the classic drama without over dramatization mixed with robins new love of the thriller but this isnt a thriller per se this is more a mystery suspense vehicle through which williams attempts to locate a sick boy and his keeper also starring sandra oh and rory culkin this suspense drama plays pretty much like a news report until williams character gets close to achieving his goal i must say that i was highly entertained though this movie fails to teach guide inspect or amuse it felt more like i was watching a guy williams as he was actually performing the actions from a third person perspective in other words it felt real and i was able to subscribe to the premise of the story all in all its worth a watch though its definitely not friday saturday night fare it rates a   from the fiend '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_train_clean[5]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(binary=True)\n",
    "cv.fit(reviews_train_clean)\n",
    "X = cv.transform(reviews_train_clean)\n",
    "X_test = cv.transform(reviews_test_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BaseLine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(binary=True)\n",
    "cv.fit(reviews_train_clean)\n",
    "X = cv.transform(reviews_train_clean)\n",
    "X_test = cv.transform(reviews_test_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Engit\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.88128\n",
      "Accuracy for C=0.05: 0.88592\n",
      "Accuracy for C=0.25: 0.8816\n",
      "Accuracy for C=0.5: 0.87776\n",
      "Accuracy for C=1: 0.87504\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "target = [1 if i < 12500 else 0 for i in range(25000)]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, target, train_size = 0.75\n",
    ")\n",
    "\n",
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "    lr = LogisticRegression(C=c)\n",
    "    lr.fit(X_train, y_train)\n",
    "    print (\"Accuracy for C=%s: %s\" \n",
    "           % (c, accuracy_score(y_val, lr.predict(X_val))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.88128\n"
     ]
    }
   ],
   "source": [
    "final_model = LogisticRegression(C=0.05)\n",
    "final_model.fit(X, target)\n",
    "print (\"Final Accuracy: %s\" \n",
    "       % accuracy_score(target, final_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.8768\n"
     ]
    }
   ],
   "source": [
    "final_model = LogisticRegression(C=0.25)\n",
    "final_model.fit(X, target)\n",
    "print (\"Final Accuracy: %s\" \n",
    "       % accuracy_score(target, final_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('excellent', 1.214118989137929)\n",
      "('perfect', 1.0614176588850035)\n",
      "('refreshing', 1.02102897303396)\n",
      "('superb', 0.9475637842873753)\n",
      "('wonderfully', 0.9340347499483456)\n",
      "--------------------------------------------\n",
      "('worst', -1.8263539438928587)\n",
      "('waste', -1.6781628000922757)\n",
      "('disappointment', -1.406995848590213)\n",
      "('poorly', -1.4016882951821332)\n",
      "('awful', -1.3764772758952484)\n"
     ]
    }
   ],
   "source": [
    "feature_to_coef = {\n",
    "    word: coef for word, coef in zip(\n",
    "        cv.get_feature_names(), final_model.coef_[0]\n",
    "    )\n",
    "}\n",
    "for best_positive in sorted(\n",
    "    feature_to_coef.items(), \n",
    "    key=lambda x: x[1], \n",
    "    reverse=True)[:5]:\n",
    "    print (best_positive)\n",
    "    \n",
    "#     ('excellent', 0.9288812418118644)\n",
    "#     ('perfect', 0.7934641227980576)\n",
    "#     ('great', 0.675040909917553)\n",
    "#     ('amazing', 0.6160398142631545)\n",
    "#     ('superb', 0.6063967799425831)\n",
    "print(\"--------------------------------------------\")\n",
    "for best_negative in sorted(\n",
    "    feature_to_coef.items(), \n",
    "    key=lambda x: x[1])[:5]:\n",
    "    print (best_negative)\n",
    "    \n",
    "#     ('worst', -1.367978497228895)\n",
    "#     ('waste', -1.1684451288279047)\n",
    "#     ('awful', -1.0277001734353677)\n",
    "#     ('poorly', -0.8748317895742782)\n",
    "#     ('boring', -0.8587249740682945)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing STOP words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Engit\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.87216\n",
      "Accuracy for C=0.05: 0.87856\n",
      "Accuracy for C=0.25: 0.8744\n",
      "Accuracy for C=0.5: 0.8736\n",
      "Accuracy for C=1: 0.87088\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "english_stop_words = stopwords.words('english')\n",
    "def remove_stop_words(corpus):\n",
    "    removed_stop_words = []\n",
    "    for review in corpus:\n",
    "        removed_stop_words.append(\n",
    "            ' '.join([word for word in review.split() \n",
    "                      if word not in english_stop_words])\n",
    "        )\n",
    "    return removed_stop_words\n",
    "\n",
    "no_stop_words_train = remove_stop_words(reviews_train_clean)\n",
    "no_stop_words_test = remove_stop_words(reviews_test_clean)\n",
    "\n",
    "cv = CountVectorizer(binary=True)\n",
    "cv.fit(no_stop_words_train)\n",
    "X = cv.transform(no_stop_words_train)\n",
    "X_test = cv.transform(no_stop_words_test)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, target, train_size = 0.75\n",
    ")\n",
    "\n",
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "    lr = LogisticRegression(C=c)\n",
    "    lr.fit(X_train, y_train)\n",
    "    print (\"Accuracy for C=%s: %s\" \n",
    "           % (c, accuracy_score(y_val, lr.predict(X_val))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Engit\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.87104\n",
      "Accuracy for C=0.05: 0.88016\n",
      "Accuracy for C=0.25: 0.87936\n",
      "Accuracy for C=0.5: 0.87584\n",
      "Accuracy for C=1: 0.87472\n",
      "Final Accuracy: 0.87736\n"
     ]
    }
   ],
   "source": [
    "def get_stemmed_text(corpus):\n",
    "    from nltk.stem.porter import PorterStemmer\n",
    "    stemmer = PorterStemmer()\n",
    "\n",
    "    return [' '.join([stemmer.stem(word) for word in review.split()]) for review in corpus]\n",
    "\n",
    "stemmed_reviews_train = get_stemmed_text(reviews_train_clean)\n",
    "stemmed_reviews_test = get_stemmed_text(reviews_test_clean)\n",
    "\n",
    "cv = CountVectorizer(binary=True)\n",
    "cv.fit(stemmed_reviews_train)\n",
    "X = cv.transform(stemmed_reviews_train)\n",
    "X_test = cv.transform(stemmed_reviews_test)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, target, train_size = 0.75\n",
    ")\n",
    "\n",
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "    lr = LogisticRegression(C=c)\n",
    "    lr.fit(X_train, y_train)\n",
    "    print (\"Accuracy for C=%s: %s\" \n",
    "           % (c, accuracy_score(y_val, lr.predict(X_val))))\n",
    "    \n",
    "final_stemmed = LogisticRegression(C=0.05)\n",
    "final_stemmed.fit(X, target)\n",
    "print (\"Final Accuracy: %s\" \n",
    "       % accuracy_score(target, final_stemmed.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Engit\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.87408\n",
      "Accuracy for C=0.05: 0.88352\n",
      "Accuracy for C=0.25: 0.8824\n",
      "Accuracy for C=0.5: 0.87952\n",
      "Accuracy for C=1: 0.87552\n",
      "Final Accuracy: 0.87376\n"
     ]
    }
   ],
   "source": [
    "def get_lemmatized_text(corpus):\n",
    "    \n",
    "    from nltk.stem import WordNetLemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return [' '.join([lemmatizer.lemmatize(word) for word in review.split()]) for review in corpus]\n",
    "\n",
    "lemmatized_reviews_train = get_lemmatized_text(reviews_train_clean)\n",
    "lemmatized_reviews_test = get_lemmatized_text(reviews_test_clean)\n",
    "\n",
    "cv = CountVectorizer(binary=True)\n",
    "cv.fit(lemmatized_reviews_train)\n",
    "X = cv.transform(lemmatized_reviews_train)\n",
    "X_test = cv.transform(lemmatized_reviews_test)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, target, train_size = 0.75\n",
    ")\n",
    "\n",
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "    lr = LogisticRegression(C=c)\n",
    "    lr.fit(X_train, y_train)\n",
    "    print (\"Accuracy for C=%s: %s\" \n",
    "           % (c, accuracy_score(y_val, lr.predict(X_val))))\n",
    "    \n",
    "final_lemmatized = LogisticRegression(C=0.25)\n",
    "final_lemmatized.fit(X, target)\n",
    "print (\"Final Accuracy: %s\" \n",
    "       % accuracy_score(target, final_lemmatized.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removed stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'isnt comedic robin williams quirky insane robin williams recent thriller fame hybrid classic drama without dramatization mixed robins new love thriller isnt thriller per se mystery suspense vehicle williams attempts locate sick boy keeper also starring sandra oh rory culkin suspense drama plays pretty much like news report williams character gets close achieving goal must say highly entertained though movie fails teach guide inspect amuse felt like watching guy williams actually performing actions third person perspective words felt real able subscribe premise story worth watch though definitely friday saturday night fare rates fiend'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_stop_words_train[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'thi isnt the comed robin william nor is it the quirki insan robin william of recent thriller fame thi is a hybrid of the classic drama without over dramat mix with robin new love of the thriller but thi isnt a thriller per se thi is more a mysteri suspens vehicl through which william attempt to locat a sick boy and hi keeper also star sandra oh and rori culkin thi suspens drama play pretti much like a news report until william charact get close to achiev hi goal i must say that i wa highli entertain though thi movi fail to teach guid inspect or amus it felt more like i wa watch a guy william as he wa actual perform the action from a third person perspect in other word it felt real and i wa abl to subscrib to the premis of the stori all in all it worth a watch though it definit not friday saturday night fare it rate a from the fiend'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmed_reviews_train[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this isnt the comedic robin williams nor is it the quirky insane robin williams of recent thriller fame this is a hybrid of the classic drama without over dramatization mixed with robin new love of the thriller but this isnt a thriller per se this is more a mystery suspense vehicle through which williams attempt to locate a sick boy and his keeper also starring sandra oh and rory culkin this suspense drama play pretty much like a news report until williams character get close to achieving his goal i must say that i wa highly entertained though this movie fails to teach guide inspect or amuse it felt more like i wa watching a guy williams a he wa actually performing the action from a third person perspective in other word it felt real and i wa able to subscribe to the premise of the story all in all it worth a watch though it definitely not friday saturday night fare it rate a from the fiend'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatized_reviews_train[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Engit\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.88416\n",
      "Accuracy for C=0.05: 0.88864\n",
      "Accuracy for C=0.25: 0.8912\n",
      "Accuracy for C=0.5: 0.89056\n",
      "Accuracy for C=1: 0.88944\n",
      "Final Accuracy: 0.89872\n"
     ]
    }
   ],
   "source": [
    "ngram_vectorizer = CountVectorizer(binary=True, ngram_range=(1, 2))\n",
    "ngram_vectorizer.fit(reviews_train_clean)\n",
    "X = ngram_vectorizer.transform(reviews_train_clean)\n",
    "X_test = ngram_vectorizer.transform(reviews_test_clean)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, target, train_size = 0.75\n",
    ")\n",
    "\n",
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "    lr = LogisticRegression(C=c)\n",
    "    lr.fit(X_train, y_train)\n",
    "    print (\"Accuracy for C=%s: %s\" \n",
    "           % (c, accuracy_score(y_val, lr.predict(X_val))))\n",
    "    \n",
    "# Accuracy for C=0.01: 0.88416\n",
    "# Accuracy for C=0.05: 0.892\n",
    "# Accuracy for C=0.25: 0.89424\n",
    "# Accuracy for C=0.5: 0.89456\n",
    "# Accuracy for C=1: 0.8944\n",
    "    \n",
    "final_ngram = LogisticRegression(C=0.5)\n",
    "final_ngram.fit(X, target)\n",
    "print (\"Final Accuracy: %s\" \n",
    "       % accuracy_score(target, final_ngram.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# word counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Engit\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.87888\n",
      "Accuracy for C=0.05: 0.88896\n",
      "Accuracy for C=0.25: 0.88928\n",
      "Accuracy for C=0.5: 0.88576\n",
      "Accuracy for C=1: 0.88176\n",
      "Final Accuracy: 0.882\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "wc_vectorizer = CountVectorizer(binary=False)\n",
    "wc_vectorizer.fit(reviews_train_clean)\n",
    "X = wc_vectorizer.transform(reviews_train_clean)\n",
    "X_test = wc_vectorizer.transform(reviews_test_clean)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, target, train_size = 0.75, \n",
    ")\n",
    "\n",
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "    lr = LogisticRegression(C=c)\n",
    "    lr.fit(X_train, y_train)\n",
    "    print (\"Accuracy for C=%s: %s\" \n",
    "           % (c, accuracy_score(y_val, lr.predict(X_val))))\n",
    "    \n",
    "# Accuracy for C=0.01: 0.87456\n",
    "# Accuracy for C=0.05: 0.88016\n",
    "# Accuracy for C=0.25: 0.87936\n",
    "# Accuracy for C=0.5: 0.87936\n",
    "# Accuracy for C=1: 0.87696\n",
    "    \n",
    "final_wc = LogisticRegression(C=0.05)\n",
    "final_wc.fit(X, target)\n",
    "print (\"Final Accuracy: %s\" \n",
    "       % accuracy_score(target, final_wc.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Engit\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.79056\n",
      "Accuracy for C=0.05: 0.824\n",
      "Accuracy for C=0.25: 0.8632\n",
      "Accuracy for C=0.5: 0.87216\n",
      "Accuracy for C=1: 0.87968\n",
      "Final Accuracy: 0.88248\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_vectorizer.fit(reviews_train_clean)\n",
    "X = tfidf_vectorizer.transform(reviews_train_clean)\n",
    "X_test = tfidf_vectorizer.transform(reviews_test_clean)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, target, train_size = 0.75\n",
    ")\n",
    "\n",
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "    lr = LogisticRegression(C=c)\n",
    "    lr.fit(X_train, y_train)\n",
    "    print (\"Accuracy for C=%s: %s\" \n",
    "           % (c, accuracy_score(y_val, lr.predict(X_val))))\n",
    "\n",
    "# Accuracy for C=0.01: 0.79632\n",
    "# Accuracy for C=0.05: 0.83168\n",
    "# Accuracy for C=0.25: 0.86768\n",
    "# Accuracy for C=0.5: 0.8736\n",
    "# Accuracy for C=1: 0.88432\n",
    "    \n",
    "final_tfidf = LogisticRegression(C=1)\n",
    "final_tfidf.fit(X, target)\n",
    "print (\"Final Accuracy: %s\" \n",
    "       % accuracy_score(target, final_tfidf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines(SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Engit\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.89296\n",
      "Accuracy for C=0.05: 0.88864\n",
      "Accuracy for C=0.25: 0.88704\n",
      "Accuracy for C=0.5: 0.88672\n",
      "Accuracy for C=1: 0.88608\n",
      "Final Accuracy: 0.8976\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "ngram_vectorizer = CountVectorizer(binary=True, ngram_range=(1, 2))\n",
    "ngram_vectorizer.fit(reviews_train_clean)\n",
    "X = ngram_vectorizer.transform(reviews_train_clean)\n",
    "X_test = ngram_vectorizer.transform(reviews_test_clean)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, target, train_size = 0.75\n",
    ")\n",
    "\n",
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "    svm = LinearSVC(C=c)\n",
    "    svm.fit(X_train, y_train)\n",
    "    print (\"Accuracy for C=%s: %s\" \n",
    "           % (c, accuracy_score(y_val, svm.predict(X_val))))\n",
    "    \n",
    "# Accuracy for C=0.01: 0.89104\n",
    "# Accuracy for C=0.05: 0.88736\n",
    "# Accuracy for C=0.25: 0.8856\n",
    "# Accuracy for C=0.5: 0.88608\n",
    "# Accuracy for C=1: 0.88592\n",
    "    \n",
    "final_svm_ngram = LinearSVC(C=0.01)\n",
    "final_svm_ngram.fit(X, target)\n",
    "print (\"Final Accuracy: %s\" \n",
    "       % accuracy_score(target, final_svm_ngram.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Engit\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.001: 0.88672\n",
      "Accuracy for C=0.005: 0.89264\n",
      "Accuracy for C=0.01: 0.89216\n",
      "Accuracy for C=0.05: 0.89088\n",
      "Accuracy for C=0.1: 0.89072\n",
      "Final Accuracy: 0.9\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "\n",
    "stop_words = ['in', 'of', 'at', 'a', 'the']\n",
    "ngram_vectorizer = CountVectorizer(binary=True, ngram_range=(1, 3), stop_words=stop_words)\n",
    "ngram_vectorizer.fit(reviews_train_clean)\n",
    "X = ngram_vectorizer.transform(reviews_train_clean)\n",
    "X_test = ngram_vectorizer.transform(reviews_test_clean)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, target, train_size = 0.75\n",
    ")\n",
    "\n",
    "for c in [0.001, 0.005, 0.01, 0.05, 0.1]:\n",
    "    \n",
    "    svm = LinearSVC(C=c)\n",
    "    svm.fit(X_train, y_train)\n",
    "    print (\"Accuracy for C=%s: %s\" \n",
    "           % (c, accuracy_score(y_val, svm.predict(X_val))))\n",
    "    \n",
    "# Accuracy for C=0.001: 0.88784\n",
    "# Accuracy for C=0.005: 0.89456\n",
    "# Accuracy for C=0.01: 0.89376\n",
    "# Accuracy for C=0.05: 0.89264\n",
    "# Accuracy for C=0.1: 0.8928\n",
    "    \n",
    "final = LinearSVC(C=0.01)\n",
    "final.fit(X, target)\n",
    "print (\"Final Accuracy: %s\" \n",
    "       % accuracy_score(target, final.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Positive and Negative features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('excellent', 0.23047714665295013)\n",
      "('perfect', 0.18507025635085939)\n",
      "('great', 0.17881800966482828)\n",
      "('wonderful', 0.1607892596271847)\n",
      "('amazing', 0.15226950252500274)\n",
      "('superb', 0.14695922772180878)\n",
      "('enjoyable', 0.14431473750335974)\n",
      "('best', 0.13064244558670104)\n",
      "('enjoyed', 0.12732762211231663)\n",
      "('fun', 0.12671723549565903)\n",
      "('today', 0.1218357629667757)\n",
      "('brilliant', 0.12065189507849217)\n",
      "('must see', 0.117547369049201)\n",
      "('fantastic', 0.11538150899949517)\n",
      "('loved', 0.11334099469542266)\n",
      "('liked', 0.11200563742048612)\n",
      "('funniest', 0.11168721821511732)\n",
      "('incredible', 0.10863100732595118)\n",
      "('wonderfully', 0.10755457353594858)\n",
      "('better than', 0.10678238074676964)\n",
      "('rare', 0.1040181340090769)\n",
      "('beautiful', 0.1036376996614285)\n",
      "('bit', 0.10192527260339772)\n",
      "('love', 0.10181871499151712)\n",
      "('well worth', 0.10117934903435798)\n",
      "('highly', 0.10095355710540657)\n",
      "('job', 0.10068804342180443)\n",
      "('watch it', 0.09981112018055724)\n",
      "('recommended', 0.09814962678181723)\n",
      "('moving', 0.09695428184817509)\n",
      "('perfectly', 0.09667794111517433)\n",
      "('refreshing', 0.0955479685204207)\n",
      "('very good', 0.0954366920782708)\n",
      "('hilarious', 0.09456058525207334)\n",
      "('especially', 0.09324807545321342)\n",
      "('gem', 0.09311316590127199)\n",
      "('subtle', 0.09275245912482506)\n",
      "('favorite', 0.09232588913151267)\n",
      "('definitely', 0.09171621530257436)\n",
      "('true', 0.09157532924873028)\n",
      "('surprised', 0.09020622511847982)\n",
      "('shows', 0.08990227741402894)\n",
      "('simple', 0.08969035382820943)\n",
      "('not only', 0.08931190625804605)\n",
      "('strong', 0.08918482180910964)\n",
      "('touching', 0.08794431212834045)\n",
      "('fascinating', 0.08679321058312263)\n",
      "('masterpiece', 0.08666986384291228)\n",
      "('both', 0.08648493468281433)\n",
      "('enjoy', 0.08607098454832926)\n",
      "('entertaining', 0.08520028053991743)\n",
      "('surprisingly', 0.08511445844153762)\n",
      "('definitely worth', 0.08362037707225972)\n",
      "('to all', 0.08346658622250228)\n",
      "('one best', 0.08314015230368896)\n",
      "('love this', 0.08298441784366391)\n",
      "('realistic', 0.08268806792866772)\n",
      "('loved this', 0.08265762773552324)\n",
      "('outstanding', 0.08259934586881008)\n",
      "('is great', 0.08185194771259234)\n",
      "('believable', 0.07965768267406768)\n",
      "('very well', 0.07952171150845071)\n",
      "('atmosphere', 0.0790479682404801)\n",
      "('solid', 0.07886809154050849)\n",
      "('pretty good', 0.07856876151630285)\n",
      "('powerful', 0.0776686076219272)\n",
      "('noir', 0.07657262209366185)\n",
      "('terrific', 0.07622227121313215)\n",
      "('tears', 0.07586704263332539)\n",
      "('plenty', 0.07571871093579484)\n",
      "('expecting', 0.07553191573616574)\n",
      "('awesome', 0.0753017536915436)\n",
      "('underrated', 0.07514187541735223)\n",
      "('makes', 0.07469656752106348)\n",
      "('was great', 0.0740273536981461)\n",
      "('classic', 0.07385363049874216)\n",
      "('always', 0.07353763017312517)\n",
      "('unique', 0.07258412470135689)\n",
      "('well', 0.0725119917184687)\n",
      "('sweet', 0.07234442320358922)\n",
      "('world', 0.07216163171571592)\n",
      "('delightful', 0.0720395389497447)\n",
      "('my favorite', 0.07160495852431238)\n",
      "('on dvd', 0.07062854010158878)\n",
      "('greatest', 0.07061619730858366)\n",
      "('enjoyed this', 0.0699377541153889)\n",
      "('subtitles', 0.06989087050426902)\n",
      "('and how', 0.0695574525782556)\n",
      "('cant wait', 0.06949994413849023)\n",
      "('heart', 0.06925715799569564)\n",
      "('beauty', 0.06921435062870035)\n",
      "('still', 0.06920972608131298)\n",
      "('nice', 0.06899357316048695)\n",
      "('is best', 0.068931703567008)\n",
      "('beautifully', 0.06891254386791948)\n",
      "('enjoyed it', 0.06785321614291656)\n",
      "('what it', 0.06694941871187085)\n",
      "('different', 0.06686890182086594)\n",
      "('finest', 0.06681198914481463)\n",
      "('my only', 0.06670449985049394)\n",
      "\n",
      "\n",
      "\n",
      "('worst', -0.359586355802234)\n",
      "('awful', -0.25540098545471396)\n",
      "('boring', -0.2404542546169319)\n",
      "('waste', -0.23777958167978938)\n",
      "('bad', -0.22229431646828982)\n",
      "('poor', -0.20207930136182842)\n",
      "('terrible', -0.19911693161147445)\n",
      "('dull', -0.18248451191680162)\n",
      "('disappointment', -0.17575626746307385)\n",
      "('poorly', -0.1737034110608417)\n",
      "('disappointing', -0.167806718430936)\n",
      "('unfortunately', -0.15749774833543073)\n",
      "('stupid', -0.15416424773289641)\n",
      "('horrible', -0.1540510157378346)\n",
      "('worse', -0.15304180198350809)\n",
      "('mess', -0.14794756878161164)\n",
      "('nothing', -0.14007349344017445)\n",
      "('lame', -0.13806269907198818)\n",
      "('save', -0.1359245824729555)\n",
      "('lacks', -0.13560833448955323)\n",
      "('oh', -0.132441388161389)\n",
      "('avoid', -0.13178224203364408)\n",
      "('ridiculous', -0.13161464074644172)\n",
      "('weak', -0.12800395919610727)\n",
      "('annoying', -0.1264821841194408)\n",
      "('fails', -0.12462870230157941)\n",
      "('badly', -0.12273300547137582)\n",
      "('script', -0.12270962089945416)\n",
      "('not good', -0.12008064855594826)\n",
      "('not worth', -0.11956611266235274)\n",
      "('laughable', -0.1180489866688535)\n",
      "('crap', -0.11308324091570751)\n",
      "('wonder', -0.11000843383804147)\n",
      "('minutes', -0.10972461960739299)\n",
      "('money', -0.10876458139655731)\n",
      "('not even', -0.10850490608513264)\n",
      "('predictable', -0.10757683091572642)\n",
      "('unless', -0.1073283869788391)\n",
      "('pointless', -0.10665303555432946)\n",
      "('pathetic', -0.1057371313821747)\n",
      "('than this', -0.10554700306645845)\n",
      "('disappointed', -0.1022932086058523)\n",
      "('way too', -0.10191820438576837)\n",
      "('unfunny', -0.09872964277709108)\n",
      "('bored', -0.0979616029763165)\n",
      "('redeeming', -0.09745884737902973)\n",
      "('one worst', -0.09672057431117288)\n",
      "('instead', -0.09646078404782124)\n",
      "('effort', -0.09582746496726323)\n",
      "('idea', -0.09534774093691827)\n",
      "('basically', -0.09528513923905388)\n",
      "('mediocre', -0.0933727786489805)\n",
      "('worst movie', -0.09250537858672554)\n",
      "('forgettable', -0.09214582828157047)\n",
      "('not very', -0.08983651965181134)\n",
      "('just not', -0.08892242089984356)\n",
      "('wooden', -0.08847660888940052)\n",
      "('cheap', -0.08797578121284971)\n",
      "('dreadful', -0.087603969288955)\n",
      "('wasted', -0.08701614262637637)\n",
      "('no', -0.0862666371552642)\n",
      "('attempt', -0.08554560060474123)\n",
      "('sadly', -0.08450691099957201)\n",
      "('not funny', -0.08357786395487303)\n",
      "('looks', -0.08315340648397992)\n",
      "('plot', -0.08294499642883021)\n",
      "('silly', -0.08173659356383609)\n",
      "('turkey', -0.08094725000369996)\n",
      "('couldnt', -0.0806017903656221)\n",
      "('not recommend', -0.08057324666583636)\n",
      "('someone', -0.08056789061652775)\n",
      "('sorry', -0.08046450289330473)\n",
      "('guess', -0.08034419750961616)\n",
      "('too many', -0.0802456427378377)\n",
      "('okay', -0.0800822897960408)\n",
      "('waste time', -0.07989343104284027)\n",
      "('uninteresting', -0.07967041656878007)\n",
      "('better', -0.07934241419477037)\n",
      "('tedious', -0.07869198504778249)\n",
      "('lousy', -0.07832367400632892)\n",
      "('pretentious', -0.07722732567553492)\n",
      "('sit through', -0.0763195315140743)\n",
      "('should have', -0.0761867384052814)\n",
      "('garbage', -0.07581738152806818)\n",
      "('premise', -0.07472699165989251)\n",
      "('grade', -0.07471923443862191)\n",
      "('material', -0.07416822409179627)\n",
      "('mstk', -0.07397410618230929)\n",
      "('starts', -0.0722394735345937)\n",
      "('interest', -0.07190374989808188)\n",
      "('joke', -0.07163005922204733)\n",
      "('hoping', -0.0710822714288269)\n",
      "('year old', -0.07038464368894168)\n",
      "('whats', -0.07038288501488325)\n",
      "('self', -0.06960252057488686)\n",
      "('sucks', -0.06948112121456876)\n",
      "('let down', -0.06930362637619114)\n",
      "('is just', -0.06924447370557425)\n",
      "('shame', -0.06910289891701421)\n",
      "('rubbish', -0.0690231397025367)\n"
     ]
    }
   ],
   "source": [
    "feature_to_coef = {\n",
    "    word: coef for word, coef in zip(\n",
    "        ngram_vectorizer.get_feature_names(), final.coef_[0]\n",
    "    )\n",
    "}\n",
    "\n",
    "for best_positive in sorted(\n",
    "    feature_to_coef.items(), \n",
    "    key=lambda x: x[1], \n",
    "    reverse=True)[:100]:\n",
    "    print (best_positive)\n",
    "    \n",
    "print(\"\\n\\n\")\n",
    "for best_negative in sorted(\n",
    "    feature_to_coef.items(), \n",
    "    key=lambda x: x[1])[:100]:\n",
    "    print (best_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "clf = LinearSVC().fit(X_train, y_train)\n",
    "filename = 'finalized_model.sav'\n",
    "pickle.dump(clf, open(filename, 'wb'))\n",
    "filename = 'finalized_model.sav'\n",
    "loaded_model = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "result = loaded_model.predict(ngram_vectorizer.transform([lemmatized_reviews_test[11800]]))\n",
    "print (result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "result = loaded_model.predict(ngram_vectorizer.transform([\"still\"]))\n",
    "print (result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "style.use(\"ggplot\")\n",
    "xx=[1,2,5,8,9.98]\n",
    "yy=[1,6,7,5,4]\n",
    "plt.scatter(xx, yy)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
